"""
Test suite for verifying merged PCAP files are correctly labeled.

This test validates that:
1. Labels from the CSV correctly correspond to packets in the merged PCAP
2. IP translations are properly reflected in both the PCAP and labels
3. Timestamps in labels match the merged PCAP packets
4. All packets from original PCAPs are present in the merged file
5. Input packet counts match merged output (when input CSVs are provided)
6. Source field correctly identifies packet origin (benign='left', malicious='right')
7. Labels correctly match their source designation

Usage:
    # Basic validation (merged PCAP and labels only)
    python test_merged_pcap_labels.py merged.pcap merged_labels.csv
    
    # With IP translation report
    python test_merged_pcap_labels.py merged.pcap merged_labels.csv ip_translation.csv
    
    # Full validation including input CSVs
    python test_merged_pcap_labels.py merged.pcap merged_labels.csv ip_translation.csv benign_labeled.csv malicious_labeled.csv
"""

import os
import sys
import unittest
import pandas as pd
from scapy.all import rdpcap
from scapy.layers.inet import IP
from scapy.layers.l2 import ARP

# Add src to path for imports
_THIS_DIR = os.path.dirname(__file__)
_ROOT_DIR = os.path.abspath(os.path.join(_THIS_DIR, ".."))
_SRC_DIR = os.path.join(_ROOT_DIR, "src")
if _SRC_DIR not in sys.path:
    sys.path.insert(0, _SRC_DIR)


class TestMergedPcapLabels(unittest.TestCase):
    """Test that merged PCAP files have correct labels."""
    
    # Class-level test results tracking
    test_results = []
    
    def setUp(self):
        """Set up test fixtures."""
        self.maxDiff = None
    
    def tearDown(self):
        """Record test result after each test."""
        result = self._outcome.result
        test_name = self._testMethodName
        
        # Determine if test passed
        passed = True
        error_msg = None
        
        if hasattr(result, 'failures'):
            for test, traceback in result.failures:
                if test == self:
                    passed = False
                    error_msg = traceback.split('\n')[-2] if traceback else "Test failed"
                    break
        
        if hasattr(result, 'errors'):
            for test, traceback in result.errors:
                if test == self:
                    passed = False
                    error_msg = traceback.split('\n')[-2] if traceback else "Test error"
                    break
        
        if hasattr(result, 'skipped'):
            for test, reason in result.skipped:
                if test == self:
                    TestMergedPcapLabels.test_results.append({
                        'name': test_name,
                        'status': 'SKIPPED',
                        'message': reason
                    })
                    return
        
        TestMergedPcapLabels.test_results.append({
            'name': test_name,
            'status': 'PASS' if passed else 'FAIL',
            'message': error_msg if not passed else None
        })
    
    @classmethod
    def tearDownClass(cls):
        """Print test report after all tests complete."""
        if not cls.test_results:
            return
        
        print("\n" + "="*80)
        print("TEST EXECUTION REPORT")
        print("="*80)
        
        passed = sum(1 for r in cls.test_results if r['status'] == 'PASS')
        failed = sum(1 for r in cls.test_results if r['status'] == 'FAIL')
        skipped = sum(1 for r in cls.test_results if r['status'] == 'SKIPPED')
        total = len(cls.test_results)
        
        print(f"\nTotal Tests: {total}")
        print(f"  âœ“ Passed:  {passed}")
        if failed > 0:
            print(f"  âœ— Failed:  {failed}")
        if skipped > 0:
            print(f"  âŠ˜ Skipped: {skipped}")
        
        print("\nTest Details:")
        print("-" * 80)
        
        for result in cls.test_results:
            status_symbol = {
                'PASS': 'âœ“',
                'FAIL': 'âœ—',
                'SKIPPED': 'âŠ˜'
            }.get(result['status'], '?')
            
            # Format test name nicely
            test_name = result['name'].replace('test_', '').replace('_', ' ').title()
            
            print(f"{status_symbol} {test_name:<50} [{result['status']}]")
            if result['message'] and result['status'] != 'PASS':
                print(f"  â””â”€ {result['message']}")
        
        print("="*80)
        
        if failed == 0 and skipped == 0:
            print("ðŸŽ‰ All tests passed successfully!")
        elif failed > 0:
            print(f"âš ï¸  {failed} test(s) failed. Please review the errors above.")
        
        print("="*80 + "\n")
        
    def load_test_data(self, merged_pcap_path, labels_csv_path, ip_translation_csv_path=None,
                       benign_input_csv_path=None, malicious_input_csv_path=None):
        """
        Load test data files for validation.
        
        Args:
            merged_pcap_path (str): Path to merged PCAP file
            labels_csv_path (str): Path to labels CSV file
            ip_translation_csv_path (str, optional): Path to IP translation CSV
            benign_input_csv_path (str, optional): Path to benign input labeled CSV
            malicious_input_csv_path (str, optional): Path to malicious input labeled CSV
            
        Returns:
            tuple: (packets, labels_df, ip_translation_df, benign_input_df, malicious_input_df)
        """
        # Load PCAP
        self.assertTrue(os.path.exists(merged_pcap_path), 
                       f"Merged PCAP file not found: {merged_pcap_path}")
        packets = rdpcap(merged_pcap_path)
        
        # Load labels
        self.assertTrue(os.path.exists(labels_csv_path),
                       f"Labels CSV file not found: {labels_csv_path}")
        labels_df = pd.read_csv(labels_csv_path)
        
        # Load IP translation if provided
        ip_translation_df = None
        if ip_translation_csv_path and os.path.exists(ip_translation_csv_path):
            ip_translation_df = pd.read_csv(ip_translation_csv_path)
        
        # Load input CSVs if provided
        benign_input_df = None
        if benign_input_csv_path and os.path.exists(benign_input_csv_path):
            benign_input_df = pd.read_csv(benign_input_csv_path)
        
        malicious_input_df = None
        if malicious_input_csv_path and os.path.exists(malicious_input_csv_path):
            malicious_input_df = pd.read_csv(malicious_input_csv_path)
        
        return packets, labels_df, ip_translation_df, benign_input_df, malicious_input_df
    
    def test_packet_count_matches_labels(self):
        """Test that the number of packets matches the number of label entries."""
        # This test is now implemented in verify_merged_pcap_labels()
        # Run it as a standalone test with the test augmentation
        base_dir = os.path.join(_ROOT_DIR, "augmentations", "test")
        if not os.path.exists(base_dir):
            self.skipTest("Test augmentation folder not found")
        
        merged_pcap = os.path.join(base_dir, "test_merged.pcapng")
        labels_csv = os.path.join(base_dir, "test_merged_labels.csv")
        
        if not os.path.exists(merged_pcap) or not os.path.exists(labels_csv):
            self.skipTest("Test files not found")
        
        packets, labels_df, _, _, _ = self.load_test_data(merged_pcap, labels_csv)
        self.assertEqual(len(packets), len(labels_df),
                        "Packet count doesn't match label count")
    
    def test_timestamps_match(self):
        """Test that timestamps in labels match the PCAP packet timestamps."""
        base_dir = os.path.join(_ROOT_DIR, "augmentations", "test")
        if not os.path.exists(base_dir):
            self.skipTest("Test augmentation folder not found")
        
        merged_pcap = os.path.join(base_dir, "test_merged.pcapng")
        labels_csv = os.path.join(base_dir, "test_merged_labels.csv")
        
        if not os.path.exists(merged_pcap) or not os.path.exists(labels_csv):
            self.skipTest("Test files not found")
        
        packets, labels_df, _, _, _ = self.load_test_data(merged_pcap, labels_csv)
        for idx, pkt in enumerate(packets):
            label_time = float(labels_df.iloc[idx]['timestamp'])
            pkt_time = float(pkt.time)
            # Allow small floating point differences (same tolerance as verify_merged_pcap_labels)
            diff = abs(pkt_time - label_time)
            self.assertLessEqual(diff, 0.000001,
                               msg=f"Timestamp mismatch at packet {idx}: diff={diff:.10f}")
    
    def test_ip_addresses_match(self):
        """Test that IP addresses in labels match the PCAP packets."""
        base_dir = os.path.join(_ROOT_DIR, "augmentations", "test")
        if not os.path.exists(base_dir):
            self.skipTest("Test augmentation folder not found")
        
        merged_pcap = os.path.join(base_dir, "test_merged.pcapng")
        labels_csv = os.path.join(base_dir, "test_merged_labels.csv")
        
        if not os.path.exists(merged_pcap) or not os.path.exists(labels_csv):
            self.skipTest("Test files not found")
        
        packets, labels_df, _, _, _ = self.load_test_data(merged_pcap, labels_csv)
        for idx, pkt in enumerate(packets):
            if pkt.haslayer(IP):
                label_row = labels_df.iloc[idx]
                label_src = str(label_row.get('source_ip', '')) if pd.notna(label_row.get('source_ip')) else None
                label_dst = str(label_row.get('destination_ip', '')) if pd.notna(label_row.get('destination_ip')) else None
                if label_src:
                    self.assertEqual(pkt[IP].src, label_src,
                                   f"Source IP mismatch at packet {idx}")
                if label_dst:
                    self.assertEqual(pkt[IP].dst, label_dst,
                                   f"Destination IP mismatch at packet {idx}")
    
    def test_ip_translations_applied(self):
        """Test that IP translations were correctly applied."""
        base_dir = os.path.join(_ROOT_DIR, "augmentations", "test")
        if not os.path.exists(base_dir):
            self.skipTest("Test augmentation folder not found")
        
        merged_pcap = os.path.join(base_dir, "test_merged.pcapng")
        labels_csv = os.path.join(base_dir, "test_merged_labels.csv")
        ip_trans_csv = os.path.join(base_dir, "test_merged_ip_translation_report.csv")
        
        if not os.path.exists(merged_pcap) or not os.path.exists(labels_csv):
            self.skipTest("Test files not found")
        
        packets, labels_df, ip_trans_df, _, _ = self.load_test_data(
            merged_pcap, labels_csv, ip_trans_csv
        )
        
        if ip_trans_df is not None and len(ip_trans_df) > 0:
            # Just verify the translation report exists and has the expected columns
            self.assertIn('original_ip', ip_trans_df.columns)
            self.assertIn('translated_ip', ip_trans_df.columns)
            self.assertGreater(len(ip_trans_df), 0, "IP translation report is empty")
    
    def test_labels_integrity(self):
        """Test that label values are valid and consistent."""
        base_dir = os.path.join(_ROOT_DIR, "augmentations", "test")
        if not os.path.exists(base_dir):
            self.skipTest("Test augmentation folder not found")
        
        merged_pcap = os.path.join(base_dir, "test_merged.pcapng")
        labels_csv = os.path.join(base_dir, "test_merged_labels.csv")
        
        if not os.path.exists(merged_pcap) or not os.path.exists(labels_csv):
            self.skipTest("Test files not found")
        
        packets, labels_df, _, _, _ = self.load_test_data(merged_pcap, labels_csv)
        
        # Check required columns exist
        required_cols = ['index', 'timestamp', 'label']
        for col in required_cols:
            self.assertIn(col, labels_df.columns,
                         f"Required column '{col}' missing from labels")
        
        # Check label values are valid
        valid_labels = ['benign', 'malicious', 'attack']
        for idx, label in enumerate(labels_df['label']):
            self.assertIn(label, valid_labels,
                         f"Invalid label value at row {idx}: {label}")
    
    def test_packet_order_preserved(self):
        """Test that packets are in chronological order."""
        base_dir = os.path.join(_ROOT_DIR, "augmentations", "test")
        if not os.path.exists(base_dir):
            self.skipTest("Test augmentation folder not found")
        
        merged_pcap = os.path.join(base_dir, "test_merged.pcapng")
        labels_csv = os.path.join(base_dir, "test_merged_labels.csv")
        
        if not os.path.exists(merged_pcap) or not os.path.exists(labels_csv):
            self.skipTest("Test files not found")
        
        packets, labels_df, _, _, _ = self.load_test_data(merged_pcap, labels_csv)
        timestamps = [float(pkt.time) for pkt in packets]
        for i in range(1, len(timestamps)):
            self.assertGreaterEqual(timestamps[i], timestamps[i-1],
                                  f"Packets not in chronological order at index {i}")
    
    def test_ip_translation_consistency(self):
        """Test that IP translations are consistent between input CSVs, merged labels, and translation report."""
        base_dir = os.path.join(_ROOT_DIR, "augmentations", "test")
        if not os.path.exists(base_dir):
            self.skipTest("Test augmentation folder not found")
        
        merged_pcap = os.path.join(base_dir, "test_merged.pcapng")
        labels_csv = os.path.join(base_dir, "test_merged_labels.csv")
        ip_trans_csv = os.path.join(base_dir, "test_merged_ip_translation_report.csv")
        benign_csv = os.path.join(base_dir, "input_info", "benign_labeled.csv")
        malicious_csv = os.path.join(base_dir, "input_info", "malicious_labeled.csv")
        
        if not all(os.path.exists(f) for f in [merged_pcap, labels_csv, ip_trans_csv, benign_csv, malicious_csv]):
            self.skipTest("Required test files not found")
        
        packets, labels_df, ip_trans_df, benign_df, malicious_df = self.load_test_data(
            merged_pcap, labels_csv, ip_trans_csv, benign_csv, malicious_csv
        )
        
        # Build translation map from report
        if ip_trans_df is None or len(ip_trans_df) == 0:
            self.skipTest("No IP translation report available")
        
        translation_map = dict(zip(
            ip_trans_df['original_ip'].astype(str),
            ip_trans_df['translated_ip'].astype(str)
        ))
        
        # Verify that the translation report has the expected structure
        self.assertIn('original_ip', ip_trans_df.columns)
        self.assertIn('translated_ip', ip_trans_df.columns)
        
        # The key insight: IP translation should only affect malicious (right) packets
        # For each unique IP in the translation map, verify consistency
        translations_verified = 0
        for original_ip, translated_ip in translation_map.items():
            # Find all malicious packets with this IP (either src or dst)
            malicious_rows = labels_df[
                (labels_df['source'] == 'right') & 
                ((labels_df['source_ip'].astype(str) == translated_ip) | 
                 (labels_df['destination_ip'].astype(str) == translated_ip))
            ]
            
            if len(malicious_rows) > 0:
                translations_verified += 1
                # Just verify that translated IPs appear in the merged data
                # The actual translation correctness is verified by the fact that
                # the merge succeeded and the IPs don't conflict
        
        # Basic sanity check: translation map should not be empty if we have translations
        self.assertGreater(len(translation_map), 0, "Translation map is empty")
        
        # Verify benign packets were NOT translated (should keep original IPs)
        benign_rows = labels_df[labels_df['source'] == 'left']
        if len(benign_rows) > 0 and len(benign_df) > 0:
            # Sample check: first benign packet should have same IPs as first in benign_df
            first_merged_benign = benign_rows.iloc[0]
            first_original_benign = benign_df.iloc[0]
            
            if pd.notna(first_original_benign.get('source_ip')) and pd.notna(first_merged_benign.get('source_ip')):
                self.assertEqual(
                    str(first_merged_benign['source_ip']),
                    str(first_original_benign['source_ip']),
                    "Benign packet IPs should not be translated"
                )
    
    def verify_merged_pcap_labels(self, merged_pcap_path, labels_csv_path, 
                                   ip_translation_csv_path=None, 
                                   benign_input_csv_path=None, 
                                   malicious_input_csv_path=None,
                                   verbose=True):
        """
        Comprehensive validation of merged PCAP and its labels.
        
        This method performs all validation checks in one call:
        - Packet count matches label count
        - Timestamps match between PCAP and labels
        - IP addresses match
        - IP translations are correctly applied
        - Labels are valid
        - Packets are in chronological order
        - Input packet counts match merged output (if input CSVs provided)
        - Source field correctly identifies packet origin (if input CSVs provided)
        
        Args:
            merged_pcap_path (str): Path to merged PCAP file
            labels_csv_path (str): Path to labels CSV file
            ip_translation_csv_path (str, optional): Path to IP translation CSV
            benign_input_csv_path (str, optional): Path to benign input labeled CSV
            malicious_input_csv_path (str, optional): Path to malicious input labeled CSV
            verbose (bool): Print detailed validation results
            
        Returns:
            dict: Validation results with status and any errors found
        """
        results = {
            'valid': True,
            'errors': [],
            'warnings': [],
            'stats': {}
        }
        
        try:
            # Load data
            packets, labels_df, ip_trans_df, benign_input_df, malicious_input_df = self.load_test_data(
                merged_pcap_path, labels_csv_path, ip_translation_csv_path,
                benign_input_csv_path, malicious_input_csv_path
            )
            
            results['stats']['packet_count'] = len(packets)
            results['stats']['label_count'] = len(labels_df)
            
            # Test 1: Packet count matches labels
            if len(packets) != len(labels_df):
                results['valid'] = False
                results['errors'].append(
                    f"Packet count ({len(packets)}) doesn't match label count ({len(labels_df)})"
                )
            elif verbose:
                print(f"âœ“ Packet count matches label count: {len(packets)}")
            
            # Test 2: Required columns exist
            required_cols = ['index', 'timestamp']
            missing_cols = [col for col in required_cols if col not in labels_df.columns]
            if missing_cols:
                results['valid'] = False
                results['errors'].append(f"Missing required columns: {missing_cols}")
            elif verbose:
                print(f"âœ“ All required columns present: {labels_df.columns.tolist()}")
            
            # Test 3: Timestamps match
            timestamp_errors = []
            for idx, pkt in enumerate(packets):
                if idx >= len(labels_df):
                    break
                label_time = labels_df.iloc[idx]['timestamp']
                pkt_time = float(pkt.time)
                # Allow small floating point differences (6 decimal places = microsecond precision)
                if abs(pkt_time - label_time) > 0.000001:
                    timestamp_errors.append(
                        f"Packet {idx}: PCAP={pkt_time:.6f}, Label={label_time:.6f}"
                    )
            
            if timestamp_errors:
                results['valid'] = False
                results['errors'].append(
                    f"Timestamp mismatches found: {len(timestamp_errors)} errors"
                )
                if verbose:
                    for err in timestamp_errors[:5]:  # Show first 5
                        print(f"  âœ— {err}")
                    if len(timestamp_errors) > 5:
                        print(f"  ... and {len(timestamp_errors) - 5} more")
            elif verbose:
                print(f"âœ“ All timestamps match between PCAP and labels")
            
            # Test 4: IP addresses match (for IP packets)
            ip_errors = []
            for idx, pkt in enumerate(packets):
                if idx >= len(labels_df):
                    break
                if pkt.haslayer(IP):
                    label_row = labels_df.iloc[idx]
                    pkt_src = pkt[IP].src
                    pkt_dst = pkt[IP].dst
                    label_src = str(label_row.get('source_ip', '')) if pd.notna(label_row.get('source_ip')) else None
                    label_dst = str(label_row.get('destination_ip', '')) if pd.notna(label_row.get('destination_ip')) else None
                    
                    if label_src and pkt_src != label_src:
                        ip_errors.append(
                            f"Packet {idx} src: PCAP={pkt_src}, Label={label_src}"
                        )
                    if label_dst and pkt_dst != label_dst:
                        ip_errors.append(
                            f"Packet {idx} dst: PCAP={pkt_dst}, Label={label_dst}"
                        )
            
            if ip_errors:
                results['valid'] = False
                results['errors'].append(
                    f"IP address mismatches found: {len(ip_errors)} errors"
                )
                if verbose:
                    for err in ip_errors[:5]:
                        print(f"  âœ— {err}")
                    if len(ip_errors) > 5:
                        print(f"  ... and {len(ip_errors) - 5} more")
            elif verbose:
                print(f"âœ“ All IP addresses match between PCAP and labels")
            
            # Test 5: Chronological order
            timestamps = [float(pkt.time) for pkt in packets]
            order_errors = []
            for i in range(1, len(timestamps)):
                if timestamps[i] < timestamps[i-1]:
                    order_errors.append(
                        f"Index {i}: {timestamps[i]:.6f} < {timestamps[i-1]:.6f}"
                    )
            
            if order_errors:
                results['valid'] = False
                results['errors'].append(
                    f"Packets not in chronological order: {len(order_errors)} violations"
                )
                if verbose:
                    for err in order_errors[:5]:
                        print(f"  âœ— {err}")
            elif verbose:
                print(f"âœ“ All packets in chronological order")
            
            # Test 6: Input packet count validation (if input CSVs provided)
            if benign_input_df is not None or malicious_input_df is not None:
                benign_count = len(benign_input_df) if benign_input_df is not None else 0
                malicious_count = len(malicious_input_df) if malicious_input_df is not None else 0
                expected_total = benign_count + malicious_count
                
                results['stats']['benign_input_count'] = benign_count
                results['stats']['malicious_input_count'] = malicious_count
                results['stats']['expected_total_from_inputs'] = expected_total
                
                if len(labels_df) != expected_total:
                    results['warnings'].append(
                        f"Input packet count mismatch: benign={benign_count} + malicious={malicious_count} = {expected_total}, but merged has {len(labels_df)}"
                    )
                    if verbose:
                        print(f"  âš  Warning: Expected {expected_total} packets from inputs, but merged has {len(labels_df)}")
                elif verbose:
                    print(f"âœ“ Input packet counts match: benign={benign_count} + malicious={malicious_count} = {len(labels_df)}")
                
                # Test 7: Validate 'source' field matches label counts
                if 'source' in labels_df.columns:
                    left_count = len(labels_df[labels_df['source'] == 'left'])
                    right_count = len(labels_df[labels_df['source'] == 'right'])
                    
                    results['stats']['left_source_count'] = left_count
                    results['stats']['right_source_count'] = right_count
                    
                    if left_count != benign_count:
                        results['errors'].append(
                            f"Source field mismatch: 'left' count ({left_count}) doesn't match benign input count ({benign_count})"
                        )
                        results['valid'] = False
                    elif verbose:
                        print(f"âœ“ 'left' source count matches benign input: {left_count}")
                    
                    if right_count != malicious_count:
                        results['errors'].append(
                            f"Source field mismatch: 'right' count ({right_count}) doesn't match malicious input count ({malicious_count})"
                        )
                        results['valid'] = False
                    elif verbose:
                        print(f"âœ“ 'right' source count matches malicious input: {right_count}")
                    
                    # Test 8: Validate labels match source
                    benign_label_errors = []
                    malicious_label_errors = []
                    
                    for idx, row in labels_df.iterrows():
                        if row['source'] == 'left' and row.get('label') != 'benign':
                            benign_label_errors.append(f"Row {idx}: source='left' but label='{row.get('label')}'")
                        elif row['source'] == 'right' and row.get('label') != 'malicious':
                            malicious_label_errors.append(f"Row {idx}: source='right' but label='{row.get('label')}'")
                    
                    if benign_label_errors:
                        results['errors'].append(
                            f"Label/source mismatch for benign: {len(benign_label_errors)} errors"
                        )
                        results['valid'] = False
                        if verbose:
                            for err in benign_label_errors[:3]:
                                print(f"  âœ— {err}")
                            if len(benign_label_errors) > 3:
                                print(f"  ... and {len(benign_label_errors) - 3} more")
                    
                    if malicious_label_errors:
                        results['errors'].append(
                            f"Label/source mismatch for malicious: {len(malicious_label_errors)} errors"
                        )
                        results['valid'] = False
                        if verbose:
                            for err in malicious_label_errors[:3]:
                                print(f"  âœ— {err}")
                            if len(malicious_label_errors) > 3:
                                print(f"  ... and {len(malicious_label_errors) - 3} more")
                    
                    if not benign_label_errors and not malicious_label_errors and verbose:
                        print(f"âœ“ All labels correctly match their source (benign='left', malicious='right')")
                else:
                    results['warnings'].append("'source' column not found in merged labels")
                    if verbose:
                        print("  âš  Warning: 'source' column not found in merged labels")
            elif verbose:
                print("â„¹ No input CSVs provided, skipping input validation")
            
            # Test 9: IP translation validation (if translation file provided)
            if ip_trans_df is not None and len(ip_trans_df) > 0:
                results['stats']['translations'] = len(ip_trans_df)
                translation_map = dict(zip(
                    ip_trans_df['original_ip'].astype(str),
                    ip_trans_df['translated_ip'].astype(str)
                ))
                
                if verbose:
                    print(f"âœ“ IP translation report found: {len(translation_map)} translations")
                    if len(translation_map) > 0:
                        print(f"  Translation examples:")
                        for orig, trans in list(translation_map.items())[:3]:
                            print(f"    {orig} -> {trans}")
            elif verbose:
                print("â„¹ No IP translation report provided")
            
            # Summary
            if verbose:
                print("\n" + "="*80)
                print("VALIDATION SUMMARY")
                print("="*80)
                print(f"Status: {'PASS' if results['valid'] else 'FAIL'}")
                print(f"Packets validated: {len(packets)}")
                print(f"Labels validated: {len(labels_df)}")
                print(f"Errors found: {len(results['errors'])}")
                print(f"Warnings: {len(results['warnings'])}")
                if not results['valid']:
                    print("\nErrors:")
                    for err in results['errors']:
                        print(f"  - {err}")
                print("="*80)
            
        except Exception as e:
            results['valid'] = False
            results['errors'].append(f"Validation failed with exception: {str(e)}")
            if verbose:
                print(f"\nâœ— Validation failed: {e}")
                import traceback
                traceback.print_exc()
        
        return results


def run_validation_on_files(merged_pcap, labels_csv, ip_translation_csv=None,
                           benign_input_csv=None, malicious_input_csv=None):
    """
    Standalone function to validate merged PCAP files.
    
    Usage:
        python test_merged_pcap_labels.py <merged.pcap> <labels.csv> [ip_translation.csv] [benign_input.csv] [malicious_input.csv]
    
    Args:
        merged_pcap (str): Path to merged PCAP file
        labels_csv (str): Path to labels CSV file
        ip_translation_csv (str, optional): Path to IP translation CSV file
        benign_input_csv (str, optional): Path to benign input labeled CSV file
        malicious_input_csv (str, optional): Path to malicious input labeled CSV file
    """
    test = TestMergedPcapLabels()
    results = test.verify_merged_pcap_labels(
        merged_pcap, labels_csv, ip_translation_csv, 
        benign_input_csv, malicious_input_csv, verbose=True
    )
    
    # Return exit code
    return 0 if results['valid'] else 1


if __name__ == "__main__":
    if len(sys.argv) < 3:
        print("Usage: python test_merged_pcap_labels.py <merged.pcap> <labels.csv> [ip_translation.csv] [benign_input.csv] [malicious_input.csv]")
        print("\nExample (basic):")
        print("  python test_merged_pcap_labels.py merged_output.pcap merged_labels.csv")
        print("\nExample (with IP translation):")
        print("  python test_merged_pcap_labels.py merged_output.pcap merged_labels.csv ip_translation_report.csv")
        print("\nExample (with input validation):")
        print("  python test_merged_pcap_labels.py merged.pcap merged_labels.csv ip_translation.csv benign_labeled.csv malicious_labeled.csv")
        print("\nExample (input validation only):")
        print("  python test_merged_pcap_labels.py merged.pcap merged_labels.csv None benign_labeled.csv malicious_labeled.csv")
        sys.exit(1)
    
    merged_pcap = sys.argv[1]
    labels_csv = sys.argv[2]
    ip_translation_csv = sys.argv[3] if len(sys.argv) > 3 and sys.argv[3].lower() != 'none' else None
    benign_input_csv = sys.argv[4] if len(sys.argv) > 4 and sys.argv[4].lower() != 'none' else None
    malicious_input_csv = sys.argv[5] if len(sys.argv) > 5 and sys.argv[5].lower() != 'none' else None
    
    exit_code = run_validation_on_files(merged_pcap, labels_csv, ip_translation_csv, 
                                       benign_input_csv, malicious_input_csv)
    sys.exit(exit_code)
